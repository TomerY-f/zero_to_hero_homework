{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working dir: /worxpace/workspace/zero-to-hero/zero_to_hero_homework/zero_to_hero_homework/exercises\n",
            "\n",
            "Dataset cherry picking: ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n",
            "Dataset size: 32033\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Reading Names Dataset\n",
        "print(f\"Working dir: {os.getcwd()}\")\n",
        "dataset_path = os.path.join(os.getcwd(), \"../makemore/names.txt\")\n",
        "words = open(dataset_path, 'r').read().splitlines()\n",
        "\n",
        "print(f\"\\nDataset cherry picking: {words[:8]}\")\n",
        "print(f\"Dataset size: {len(words)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Starter Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapping index to string: {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "Mapping size: 27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(f\"Mapping index to string: {itos}\")\n",
        "vocabulary_size = len(itos)\n",
        "print(f\"Mapping size: {vocabulary_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "Features: torch.Size([182625, 8]), torch.int64\n",
            "Labels: torch.Size([182625]), torch.int64\n",
            "Dev:\n",
            "Features: torch.Size([22655, 8]), torch.int64\n",
            "Labels: torch.Size([22655]), torch.int64\n",
            "Test:\n",
            "Features: torch.Size([22866, 8]), torch.int64\n",
            "Labels: torch.Size([22866]), torch.int64\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "\n",
        "block_size = 8 \n",
        "dev_index = 0.8 #80% Training.\n",
        "test_index = 0.9 #10% dev, 10% test.\n",
        "\n",
        "# build the datasetc\n",
        "def build_dataset(dataset = list, block_size = int):\n",
        "  # block_size: context length, how many characters do we take to predict the next one?\n",
        "  # returns: X as input features in size of contect length, Y as the labels.\n",
        "  \n",
        "  X, Y = [], []\n",
        "  for w in dataset:\n",
        "    \n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "    \n",
        "  X = torch.tensor(X).to(device)\n",
        "  Y = torch.tensor(Y).to(device)\n",
        "  print(f\"Features: {X.shape}, {X.dtype}\\nLabels: {Y.shape}, {Y.dtype}\")\n",
        "  return X, Y\n",
        "  \n",
        "\n",
        "# Split the dataset to train ; dev/validation ; test\n",
        "random.seed(SEED) # Set seed for reproducibility\n",
        "random.shuffle(words)\n",
        "\n",
        "\n",
        "dev_dataset_index = int(dev_index*len(words))\n",
        "test_dataset_index = int(test_index*len(words))\n",
        "\n",
        "print(\"Train:\")\n",
        "Xtr, Ytr = build_dataset(words[:dev_dataset_index], block_size=block_size)\n",
        "print(\"Dev:\")\n",
        "Xdev, Ydev = build_dataset(words[dev_dataset_index:test_dataset_index], block_size=block_size)\n",
        "print(\"Test:\")\n",
        "Xte, Yte = build_dataset(words[test_dataset_index:], block_size=block_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CloXMPL2iL6n"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def split_loss(split, model):\n",
        "    x, y = {\n",
        "        \"train\": (Xtr, Ytr),\n",
        "        \"valid\": (Xdev, Ydev),\n",
        "        \"test\": (Xte, Yte)\n",
        "    }[split]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vA-i4sx_iM2T"
      },
      "outputs": [],
      "source": [
        "def sample(model):\n",
        "    # sampling from the model\n",
        "    for _ in range(20):\n",
        "        out = []\n",
        "        context = [0] * block_size\n",
        "        while True:\n",
        "            # Forward pass\n",
        "            logits = model(torch.tensor([context]).to(device))\n",
        "            probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "            ix = torch.multinomial(probs, num_samples = 1).item()\n",
        "\n",
        "            # Shift the Context Window\n",
        "            context = context[1:] + [ix]\n",
        "\n",
        "            if ix == 0:\n",
        "                break\n",
        "\n",
        "            out.append(ix)\n",
        "        \n",
        "        print(\"\".join(itos[i] for i in out))\n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# E01: using torch.nn Module instead of custom classes\n",
        "\n",
        "- I commented the batchnorm parts since it (surprisingly) made the model worse\n",
        "- the transpose lines before and after the batchnorm since the implementation of custom class `BatchNorm1d` in the original video has the input in format (N, L, C) instead of (N, C, L) as in the torch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FlattenConsecutive(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()  # Initialize parent nn.Module class\n",
        "        self.n = n\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape  # B=batch size, T=sequence length, C=channels\n",
        "        # Reshape while keeping 3D shape even when T//self.n == 1\n",
        "        x = x.contiguous().view(B, T//self.n, C*self.n)\n",
        "        return x\n",
        "    \n",
        "# Create a custom layer for transpose+batchnorm+transpose\n",
        "class BatchNormWithTranspose(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm1d(n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # (N, L, C) -> (N, C, L)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.bn(x)\n",
        "        # (N, C, L) -> (N, L, C)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_juxHbodiObu"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, vocabulary_size, n_embed, n_hidden):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Embedding\n",
        "            nn.Embedding(vocabulary_size, n_embed),\n",
        "            # block 1\n",
        "            FlattenConsecutive(2), \n",
        "            nn.Linear(n_embed * 2, n_hidden, bias=False),\n",
        "            #BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # block 2\n",
        "            FlattenConsecutive(2),\n",
        "            nn.Linear(n_hidden * 2, n_hidden, bias=False),\n",
        "            #BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # block 3\n",
        "            FlattenConsecutive(2),\n",
        "            nn.Linear(n_hidden * 2, n_hidden, bias=False),\n",
        "            #BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # output\n",
        "            nn.Linear(n_hidden, vocabulary_size, bias=False),\n",
        "        )\n",
        "        \n",
        "    def weights_init(self):\n",
        "        if isinstance(self.model, nn.Linear):\n",
        "            nn.init.kaiming_normal_(self.model.weight, mode='fan_in', nonlinearity='tanh')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.forward(x)\n",
        "        return x.squeeze(1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Init The Model, weights and Training\n",
        "## E02: beating the 1.993 validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_embed = 32\n",
        "n_hidden = 256\n",
        "\n",
        "model = Model(vocabulary_size, n_embed, n_hidden).to(device)\n",
        "model.weights_init()\n",
        "model(Xtr[:10]);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_aRKJp5A9m3",
        "outputId": "0a456dc0-dcb3-40ac-e28b-f3e0c0f9a36f"
      },
      "outputs": [],
      "source": [
        "def train_model(model, Xtr, Ytr, optimizer, scheduler, batch_size, epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    dev_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        for i in range(0, len(Xtr), batch_size):\n",
        "            x = Xtr[i:i+batch_size]\n",
        "            y = Ytr[i:i+batch_size]\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        train_loss = split_loss('train', model)\n",
        "        dev_loss = split_loss('valid', model)\n",
        "        train_losses.append(train_loss)\n",
        "        dev_losses.append(dev_loss)\n",
        "\n",
        "        scheduler.step(dev_loss)\n",
        "\n",
        "        print(f\"epoch : {epoch} train_loss : {train_loss} dev_loss : {dev_loss}\")\n",
        "    \n",
        "    return train_losses, dev_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[62], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_losses, dev_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mYtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, Xtr, Ytr, optimizer, scheduler, batch_size, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m Ytr[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, Xtr, Ytr, optimizer, scheduler, batch_size, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m Ytr[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "train_losses, dev_losses = train_model(model, \n",
        "                                       Xtr, \n",
        "                                       Ytr, \n",
        "                                       optimizer, \n",
        "                                       scheduler, \n",
        "                                       batch_size, \n",
        "                                       epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ynl_vofcAvDf"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"wave_net_bn_best_pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Td-jcyFHikIE",
        "outputId": "74643700-c561-4c83-976e-24c48730fad9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fff19b29900>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot train and dev losses\n",
        "plt.plot(train_losses, label = 'train')\n",
        "plt.plot(dev_losses, label = 'dev')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzDjIkqX6Uev",
        "outputId": "3c870a78-73fc-4ccc-efec-b1beb7227f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 1.736\n",
            "Validation Loss: 1.977\n",
            "Test Loss: 1.974\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training Loss: {split_loss('train', model):0.3f}\")\n",
        "print(f\"Validation Loss: {split_loss('valid', model):0.3f}\")\n",
        "print(f\"Test Loss: {split_loss('test', model):0.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7TWv5Uqrn-4",
        "outputId": "1a91fe4b-2bb3-4d6d-9091-8f793b7286d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kayfen\n",
            "sky\n",
            "zhad\n",
            "carman\n",
            "graceligi\n",
            "evoluwa\n",
            "adu\n",
            "weslyn\n",
            "kaiken\n",
            "abriona\n",
            "kius\n",
            "gendomya\n",
            "monoka\n",
            "hehar\n",
            "sultan\n",
            "elizerda\n",
            "jatavis\n",
            "zerika\n",
            "mireal\n",
            "mack\n"
          ]
        }
      ],
      "source": [
        "sample(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # E03: Using Convolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelCnn(nn.Module):\n",
        "    def __init__(self, vocabulary_size, n_embed, n_hidden, kernel_size, padding, stride=1):\n",
        "        super(ModelCnn, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Embedding\n",
        "            nn.Embedding(vocabulary_size, n_embed),\n",
        "            # block 1\n",
        "            # Replace Linear with Conv1d\n",
        "            # Need to transpose for Conv1d which expects (batch, channels, sequence_length)\n",
        "            Lambda(lambda x: x.transpose(1, 2)),\n",
        "            nn.Conv1d(n_embed, n_hidden, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride, bias=False),\n",
        "            Lambda(lambda x: x.transpose(1, 2)),\n",
        "            BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # block 2\n",
        "            Lambda(lambda x: x.transpose(1, 2)),\n",
        "            nn.Conv1d(n_hidden, n_hidden, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride, bias=False),\n",
        "            Lambda(lambda x: x.transpose(1, 2)),\n",
        "            BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # block 3\n",
        "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
        "            BatchNormWithTranspose(n_hidden),\n",
        "            nn.Tanh(),\n",
        "            # output\n",
        "            Lambda(lambda x: x.squeeze(-1)),\n",
        "            nn.Linear(n_hidden, vocabulary_size, bias=False),\n",
        "        )\n",
        "        \n",
        "    def weights_init(self):\n",
        "        for m in self.model:\n",
        "            if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='tanh')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "# Helper class for the transpose operations\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_embed = 25\n",
        "n_hidden = 80\n",
        "kernel_size = 3\n",
        "padding = 1\n",
        "\n",
        "model = ModelCnn(\n",
        "    vocabulary_size= vocabulary_size,\n",
        "    n_embed= n_embed,\n",
        "    n_hidden= n_hidden,\n",
        "    kernel_size= kernel_size,\n",
        "    padding= padding).to(device)\n",
        "model(Xtr[:10]);\n",
        "train_losses = []\n",
        "dev_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected target size [64, 27], got [64]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 6\u001b[0m train_losses, dev_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mYtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, Xtr, Ytr, optimizer, scheduler, batch_size, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m Ytr[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [64, 27], got [64]"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "train_losses, dev_losses = train_model(model, \n",
        "                                       Xtr, \n",
        "                                       Ytr, \n",
        "                                       optimizer, \n",
        "                                       scheduler, \n",
        "                                       batch_size, \n",
        "                                       epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot train and dev losses\n",
        "plt.plot(train_losses, label = 'train')\n",
        "plt.plot(dev_losses, label = 'dev')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Training Loss: {split_loss('train', model):0.3f}\")\n",
        "print(f\"Validation Loss: {split_loss('valid', model):0.3f}\")\n",
        "print(f\"Test Loss: {split_loss('test', model):0.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelCnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_embed, n_hidden, n_layers):\n",
        "        super(ModelCnn, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, n_embed)\n",
        "        self.fc1 = nn.Linear(n_embed, n_hidden, bias=False)\n",
        "\n",
        "        for i in range(n_layers):\n",
        "            setattr(self, f\"conv1d_{i}\", nn.Conv1d(in_channels=n_hidden, out_channels=n_hidden, kernel_size=2, stride=2, bias=False, dilation=1, padding=0))\n",
        "            setattr(self, f\"bn{i}\", nn.BatchNorm1d(n_hidden))\n",
        "    \n",
        "\n",
        "        self.fc2 = nn.Linear(n_hidden, vocab_size, bias=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = x.transpose(1,2)\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            conv1d = getattr(self, f\"conv1d_{i}\")\n",
        "            bn = getattr(self, f\"bn{i}\")\n",
        "            x = conv1d(x)\n",
        "\n",
        "            x = bn(x)\n",
        "            x = F.tanh(x)\n",
        "\n",
        "        x = x.squeeze(-1)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (micromamba)",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
