{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Reading Names Dataset\n",
    "print(f\"Working dir: {os.getcwd()}\")\n",
    "dataset_path = os.path.join(os.getcwd(), \"../makemore/names.txt\")\n",
    "words = open(dataset_path, 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring Dataset\n",
    "print(f\"first 10 words{words[:10]}\")\n",
    "print(f\"length of words: {len(words)}\")\n",
    "print(f\"min word length {min(len(w) for (w) in words)} and max word length {max(len(w) for (w) in words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of characters (a -> z)\n",
    "# Adding '.' as a word starter.\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "# bi string to index as an input - 2 characters.\n",
    "combinations_in_bigram = [ch1 + ch2 for ch1 in chars for ch2 in chars]\n",
    "\n",
    "# Make a dictionary of character to index\n",
    "bi_stoi = {s: i+len(chars) for i, s in enumerate(combinations_in_bigram)} \n",
    "\n",
    "for i in range(len(chars)):\n",
    "    bi_stoi['.'+chars[i]] =  i \n",
    "\n",
    "# single string to index\n",
    "si_stoi = {s:i+1 for i,s in enumerate(chars)} \n",
    "si_stoi['.'] = 0\n",
    "\n",
    "# Index to string:\n",
    "bi_itos = {i:s for s,i in bi_stoi.items()}\n",
    "si_itos = {i:s for s,i in si_stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics approach (using counting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All combinations counter:\n",
    "# N gather all the possible bi-characters with the correspond next single character in the dataset, and put them with index.\n",
    "# Makes a trigram 2characters + next 1character as a label.\n",
    "# '.' use for end / start of a word character.\n",
    "N = torch.zeros((27*27, 27), dtype=torch.int32, device=device)\n",
    "\n",
    "# Getting the Bigrams\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  \n",
    "  for i in range(len(chs) - 2):  \n",
    "    ch1_2 = chs[i] + chs[i + 1]  \n",
    "    ch3 = chs[i + 2] \n",
    "    \n",
    "    ix1 = bi_stoi[ch1_2]\n",
    "    ix2 = si_stoi[ch3]\n",
    "    \n",
    "    N[ix1, ix2] += 1\n",
    "    \n",
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(300,300))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "\n",
    "for i in range(len(bi_itos)):\n",
    "    for j in range(len(si_itos)):\n",
    "        chstr = bi_itos[i] + si_itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_loss(input_list=list):\n",
    "  log_likelihood = 0.0\n",
    "  n = 0\n",
    "\n",
    "  for w in input_list:\n",
    "  #for w in [\"andrejq\"]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    \n",
    "    for i in range(len(chs) - 2):  \n",
    "      ch1_2 = chs[i] + chs[i + 1]  \n",
    "      ch3 = chs[i + 2] \n",
    "      \n",
    "      ix1 = bi_stoi[ch1_2]\n",
    "      ix2 = si_stoi[ch3]\n",
    "      \n",
    "      prob = P[ix1, ix2]\n",
    "      logprob = torch.log(prob)\n",
    "      log_likelihood += logprob\n",
    "      n += 1\n",
    "\n",
    "  print(f'log_likelihood = {log_likelihood}')\n",
    "  nll = -log_likelihood\n",
    "  print(f'Negative log likelihood = {nll}')\n",
    "  print(f'\"Normalized Negative log Likelihood = {nll/n}')\n",
    "  \n",
    "print(\"Training Loss:\")\n",
    "count_loss(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483147)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(si_itos[ix])\n",
    "    \n",
    "    if si_itos[ix] == '.':\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach - Train on layer net:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".e m\n",
      "em m\n",
      "mm a\n",
      "ma .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of bigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  \n",
    "  for i in range(len(chs) - 2):  \n",
    "    ch1_2 = chs[i] + chs[i + 1]  \n",
    "    ch3 = chs[i + 2] \n",
    "    \n",
    "    ix1 = bi_stoi[ch1_2]\n",
    "    ix2 = si_stoi[ch3]\n",
    "  \n",
    "    print(ch1_2, ch3)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9558465480804443\n",
      "0.010289459489285946\n",
      "0.010287914425134659\n",
      "0.010286342352628708\n",
      "0.01028474047780037\n",
      "0.01028322521597147\n",
      "0.010281695984303951\n",
      "0.01028006337583065\n",
      "0.01027856394648552\n",
      "0.010277005843818188\n",
      "0.010275489650666714\n",
      "0.01027395948767662\n",
      "0.01027246005833149\n",
      "0.010270914994180202\n",
      "0.010269427672028542\n",
      "0.010267884470522404\n",
      "0.010266412049531937\n",
      "0.010264954529702663\n",
      "0.010263453237712383\n",
      "0.010262012481689453\n",
      "0.010260495357215405\n",
      "0.01025899313390255\n",
      "0.01025755051523447\n",
      "0.010256136767566204\n",
      "0.010254680179059505\n",
      "0.010253236629068851\n",
      "0.01025182381272316\n",
      "0.010250350460410118\n",
      "0.01024889200925827\n",
      "0.010247508063912392\n",
      "0.010246078483760357\n",
      "0.010244665667414665\n",
      "0.010243279859423637\n",
      "0.010241835378110409\n",
      "0.010240377858281136\n",
      "0.010239021852612495\n",
      "0.010237605310976505\n",
      "0.010236222296953201\n",
      "0.010234850458800793\n",
      "0.010233482345938683\n",
      "0.010232064872980118\n",
      "0.010230679996311665\n",
      "0.010229322127997875\n",
      "0.01022795308381319\n",
      "0.010226581245660782\n",
      "0.010225254110991955\n",
      "0.010223898105323315\n",
      "0.0102225411683321\n",
      "0.010221199132502079\n",
      "0.010219858959317207\n",
      "0.010218500159680843\n",
      "0.010217159986495972\n",
      "0.010215830989181995\n",
      "0.01021447405219078\n",
      "0.010213145986199379\n",
      "0.010211818851530552\n",
      "0.010210506618022919\n",
      "0.010209223255515099\n",
      "0.010207864455878735\n",
      "0.010206582024693489\n",
      "0.0102052828297019\n",
      "0.010203953832387924\n",
      "0.010202640667557716\n",
      "0.010201328434050083\n",
      "0.010200029239058495\n",
      "0.01019873097538948\n",
      "0.010197446681559086\n",
      "0.010196147486567497\n",
      "0.010194848291575909\n",
      "0.010193593800067902\n",
      "0.010192339308559895\n",
      "0.010191009379923344\n",
      "0.01018975768238306\n",
      "0.010188501328229904\n",
      "0.010187231935560703\n",
      "0.010185888037085533\n",
      "0.010184647515416145\n",
      "0.010183376260101795\n",
      "0.010182106867432594\n",
      "0.010180868208408356\n",
      "0.010179612785577774\n",
      "0.010178370401263237\n",
      "0.010177099145948887\n",
      "0.010175875388085842\n",
      "0.010174620896577835\n",
      "0.010173410177230835\n",
      "0.01017215196043253\n",
      "0.010170867666602135\n",
      "0.01016965601593256\n",
      "0.010168401524424553\n",
      "0.010167161002755165\n",
      "0.010165919549763203\n",
      "0.010164723731577396\n",
      "0.010163497179746628\n",
      "0.010162253864109516\n",
      "0.010161058977246284\n",
      "0.010159848257899284\n",
      "0.010158590972423553\n",
      "0.010157408192753792\n",
      "0.010156183503568172\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((len(N), 27), generator=g, requires_grad=True)\n",
    "\n",
    "ephocs = 100\n",
    "for k in range(ephocs):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=len(N)).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Inference and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmxzedmdmlkurkwcqzktxhkwstzymjtnaitrlgfakzkhtuwkskmxypubptvhrggltzs.\n",
      "iozyeqckxujjwgtedmakklevkmcskdmuhtkgvgfnywftlspwhucjmngvtahtvsk.\n",
      "ysfcxdmngslhpfnwuiqbnxwnrzywnmkwkwmkwesu.\n",
      "fkxmt.\n",
      "gcckgjbpuhbsvatubmuyexqevacmabxmcmahurwncvxmvpfkllmdmavjzsobdmcsoe.\n",
      "\n",
      "Training Loss:\n",
      "log_likelihood = -410414.96875\n",
      "Negative log likelihood = 410414.96875\n",
      "\"Normalized Negative log Likelihood = 2.092747449874878\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  \n",
    "  while True:\n",
    "    # ----------\n",
    "    # When Counting:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    \n",
    "    # now we use the softmax of the logits\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=len(N)).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(si_itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))\n",
    "  \n",
    "print(\"\\nTraining Loss:\")\n",
    "count_loss(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
